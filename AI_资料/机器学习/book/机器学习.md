[6 Books Machine Learning ](https://medium.com/age-of-awareness/6-books-machine-learning-engineers-should-read-during-lockdown-d24e7bfa453c)

1. The Hundred-Page Machine Learning Book
I absolutely love this book. This is the book you need to grok and master machine learning concepts. It explains various machine learning topics in 100 pages in detail and is very academic in its approach. It’s endorsed by reputed leaders — the Director of Research at Google, Peter Norvig and Sujeet Varakhedi, Head of Engineering at eBay.

The Hundred-Page Machine Learning Book (Image source and Credit: Amazon books)
Who can read this book: Budding to experienced ML engineers
Topics covered —
Supervised and unsupervised learning
Support vector machines
Neural networks, ensemble methods, gradient descent, cluster analysis, and dimensionality reduction, autoencoders, and transfer learning
Feature engineering and hyperparameter tuning
Author — Andriy Burkov
About the author —
Andriy is a dad of two and a machine learning expert based in Quebec City, Canada. He has a Ph.D. in Artificial Intelligence and he has been leading a team of machine learning developers at Gartner.
His specialty is natural language processing and conversational interfaces. His team works on building state-of-the-art multilingual text extraction and normalization systems for production, using both shallow and deep learning technologies.
Authors Github: https://github.com/aburkov
Get it here: https://amzn.to/3a12MwV
2. The Elements of Statistical Learning: Data Mining, Inference, and Prediction
If you are love statistics and want to learn ML from the statistics perspective then this book is a valuable resource. This book emphasizes mathematical derivations to explain the underlying concepts of a machine learning algorithm. The pre-requisite for this book is a thorough understanding of statistics and linear algebra.

The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Image source and Credit: Amazon books)
Authors — Trevor Hastie, Robert Tibshirani, and Jerome Friedman
Who can read this book: Experience ML engineers.
Topics covered —
Supervised learning and unsupervised learning.
Neural networks, support vector machines, classification trees and boosting
Graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering.
About the authors —
Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and the environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting. (Source: Springer)
Get it here: https://amzn.to/3b3JWXf
3. Hands-on Machine Learning Scikit-Learn, Keras & TensorFlow
Hands-on exercises and implementations are as important as a thorough understanding of the concepts. This book makes sure that you play around with codes, examples and build your own neural nets by offering a detailed theory with hands-on on neural nets. The breadth of information covered is quite wide and the writing is extremely clear, easy to read, written in impeccable English. This book assumes that you are an absolute beginner who knows close to nothing about Machine Learning and want to learn the intricacies of Machine Learning.

Hands-on Machine Learning Scikit-Learn, Keras & TensorFlow (Image source and Credit: Amazon books)
Authors — Aurélien Géron
Who can read this book: Beginner ML Enthusiast/Engineers
Topics covered —
Machine-learning project end-to-end using Scikit-learn
Deep dive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learning
Explore in detail the neural nets, techniques for training and scaling deep neural nets
Explore support vector machines, decision trees, random forests, and ensemble methods
How to use the TensorFlow library to build and train neural nets
About the author —
Aurélien Géron is a machine learning consultant and trainer. A former Googler, he was the product manager for YouTube’s video classification team.. He was also a founder and CTO of Wifirst and a founder and CTO of two consulting firms — Polyconseil (telecom, media, and strategy) and Kiwisoft (machine learning and data privacy).
Author’s Github — https://github.com/ageron
Get it here: https://amzn.to/2yNC7Xt
4. Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow
This was the first book I purchased when I started out with Machine Learning and I don’t regret it at all. The beauty of this book is that it focusses heavily on practical code examples. If you know some Python and you want to use machine learning and deep learning then pick up this book. This book is written for developers and data scientists who want to build practical machine learning and deep learning codes and for anyone who wants to teach the computer how to learn from data. The authors of the book Raschka and Mirjalili break difficult concepts down into language that a layperson can easily understand while building and learning these codes/examples within real-world contexts.

Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow (Image source and Credit: Amazon books)
Authors — Sebastian Raschka and Vahid Mirjalili
Who can read this book: Beginner ML Enthusiast/Engineers
Topics covered —
Learn how to apply machine learning to image classification, sentiment analysis, intelligent web applications, etc
Master the frameworks, models, and techniques that enable machines to learn from data and predict continuous target outcomes using regression analysis
Use Scikit-learn for machine learning and TensorFlow for deep learning and learn the best practices for evaluating and tuning models
Build and train neural networks, GANs etc
Learn how to use social media data for sentiment analysis
About the author —
Sebastian Raschka is an Assistant Professor of Statistics at the University of Wisconsin-Madison focusing on machine learning and deep learning research. Some of his recent research methods have been applied to solving problems in the field of biometrics for imparting privacy to face images. His research focus areas include the development of methods related to model evaluation in machine learning, deep learning for ordinal targets, and applications of machine learning to computational biology.
Author’s GitHub — https://github.com/rasbt
Vahid Mirjalili obtained his Ph.D. in mechanical engineering working on novel methods for large-scale, computational simulations of molecular structures. Currently, he is focusing his research efforts on applications of machine learning in various computer vision projects at the Department of Computer Science and Engineering at Michigan State University. He recently joined 3M Company as a research scientist, where he uses his expertise and applies state-of-the-art machine learning and deep learning techniques to solve real-world problems in various applications to make life better.
Author’s Github — https://github.com/vmirly
Get it here : https://amzn.to/2xhutV8
5.Machine Learning: The Art and Science of Algorithms that Make Sense of Data
This book is hard to read but in the end, it’s worth it. The author of the book uses the example-based approach that begins by discussing how a spam filter works, which gives an immediate introduction to machine learning in action without giving a lot of importance to the technicalities. This book has a lot of mathematical jargon and requires a thorough understanding of linear Algebra.

Machine Learning: The Art and Science of Algorithms that Make Sense of Data (Image source and Credit: Amazon books)
Authors — Peter Flach
Who can read this book — Beginner to Experienced Machine Learning Engineers
Topics covered —
The main focus is given on covering a Wide range of logical, geometric and statistical models and state-of-the-art topics such as matrix factorization and ROC analysis.
About the author —
Peter Flach is a Professor of Artificial Intelligence at the University of Bristol. His main research area is — mining highly-structured data and the evaluation and improvement of machine learning models using ROC analysis. He is also Editor-in-Chief of the Machine Learning journal.
Get it here : https://amzn.to/3cekezu
6. Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series)
I love this book for this book unifies the many different types of probabilistic models used in artificial intelligence. This book covers a variety of models, ranging from Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. Probabilistic graphical models are a powerful framework for representing complex domains using probability distributions, with numerous applications in machine learning, computer vision, natural language processing, and computational biology.

Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series) (Image source and Credit: Amazon books)
Authors — Daphne Koller and Nir Friedman
Who can read this book — Experienced Machine Learning Engineers
Topics covered —
Bayesian networks, undirected Markov networks, discrete and continuous models
Probabilistic graphical models
About the authors —
Daphne Koller is a Professor in the Department of Computer Science at Stanford University. Her main research focus is on using probabilistic models and machine learning to understand complex domains that involve large amounts of uncertainty. (Source: Stanford AI Lab)
Nir Friedman is a Professor in the Department of Computer Science and Engineering at Hebrew University. His areas of interest are — Inference and learning in probabilistic models which involve work on representation, inference, and learning with Bayesian networks and related representations, with applications to concept learning, data mining. Computational Biology which focusses on applying probabilistic models to understand biological systems and to analyze data collected from biological sources, such as protein and DNA sequences. (Source: Stanford AI Lab)
