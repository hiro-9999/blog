# 高精細の3DCG映像を裸眼
https://www.sony.jp/CorporateCruise/Press/202010/20-1016/


https://journal.ntt.co.jp/article/3870


　これを開発したのはフリーランスエンジニアのROBAさん（＠vjroba）。この仕組みを他のさまざまなディスプレイやプロジェクターでも再現するためのソフトウェア「Portalgraph」を製作したという。
 https://www.itmedia.co.jp/news/articles/2108/27/news161.html


本来このソフトを使う際には、実際にその場で映像を見る人が台湾HTCの位置トラッキングデバイス「Viveトラッカー」を頭に装着する。トラッカーで取得した頭の位置とモニターやプロジェクターの位置関係に応じて、モニターに映像を出力。冒頭の動画では、カメラにトラッカーを装着し、カメラの位置に合わせて映像を変えている。


https://portalgraph.booth.pm/items/3213218

https://togetter.com/li/1389447


Viveトラッカーで顔を追跡　3Dメガネを使えば立体視にも対応
　本来このソフトを使う際には、実際にその場で映像を見る人が台湾HTCの位置トラッキングデバイス「Viveトラッカー」を頭に装着する。トラッカーで取得した頭の位置とモニターやプロジェクターの位置関係に応じて、モニターに映像を出力。冒頭の動画では、カメラにトラッカーを装着し、カメラの位置に合わせて映像を変えている。

　実際に見る際には3Dメガネを使うことで立体視にも対応する。アナグリフ方式（いわゆる赤青メガネ）や液晶シャッター方式（センサーが光を検知すると、一定のフレームごとに左右の目で見える映像を切り替える方式）の3Dメガネを利用者が掛け、映像側もそれに応じたコンテンツを表示することで両目による奥行き感も感じられるようになる。

　3Dプロジェクターやスクリーンも含め独自のハードウェアを使う必要はなく、既製品だけで立体的に見える映像を再生できるのが特徴だ。冒頭の映像の場合、両目で立体視するには3Dメガネが必要となるが、裸眼でも片目で見れば立体感は得られるという。
 
 
 https://www.vive.com/jp/accessory/vive-tracker/
 
 https://twitter.com/vjroba
